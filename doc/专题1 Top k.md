1. top K问题

topk问题有两种考法：


- 可写代码的（已经在code中实现，主要是用堆排和快排实现）
- 考察思路的

具体到海量数据处理，无非是从时间和空间上来考量

- 时间：精妙的算法和数据结构
- 空间：分而治之

方法论：

- 分而治之/hash映射 + hash统计/hashmap + 堆/快/归并排序
- 双层桶划分
- bloom filter / bitmap
- tried树 / 数据库 / 倒排索引
- 外排序
- Hadoop/MapReduce

例子：

1. 1G大小的文件，每一行一个单词，不超过16字节，内存限制1M，返回频率最高的前100个

答： 先遍历1G的大文件，按照Hash%1000取模，将大文件映射成1000个小文件，保证相同的词分到同一个小文件中，，这样小文件就可以放到内存中，在每个小文件中使用hashmap，以单词为key，出现次数为value，然后用最小堆得到每个小文件出现频数最多的100个单词，最后进行归并排序。